{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2924bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the methods/processes\n",
    "methods = ['default_essay','self_consistency_essay_n3', 'self_consistency_essay_n5', 'self_discover_essay']\n",
    "\n",
    "# Create a dictionary to store all results\n",
    "results_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75a9984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single JSON file and calculate the aggregate score\n",
    "    Returns: (model_name, total_score, num_questions, normalized_score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract model name from filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Remove 'evaluated_results_' prefix and '.json' suffix, then split by '__'\n",
    "        model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "        \n",
    "        # Calculate total self_grade_score\n",
    "        total_score = 0\n",
    "        num_questions = 0\n",
    "        \n",
    "        for item in data:\n",
    "            if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                total_score += item['self_grade_score']\n",
    "                num_questions += 1\n",
    "        \n",
    "        # Calculate normalized score (total achieved / total possible)\n",
    "        # Total possible = num_questions * 7\n",
    "        # normalized_score = total_score / (num_questions * 7) if num_questions > 0 else 0\n",
    "        normalized_score = total_score / 149 if num_questions > 0 else 0\n",
    "        \n",
    "        return model_name, total_score, num_questions, normalized_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a5aa5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for scores over 7...\n",
      "============================================================\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_6\n",
      "   Question Index: 6\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_7\n",
      "   Question Index: 7\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_8\n",
      "   Question Index: 8\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_9\n",
      "   Question Index: 9\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_10\n",
      "   Question Index: 10\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_11\n",
      "   Question Index: 11\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_12\n",
      "   Question Index: 12\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_13\n",
      "   Question Index: 13\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_14\n",
      "   Question Index: 14\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_15\n",
      "   Question Index: 15\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_16\n",
      "   Question Index: 16\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_18\n",
      "   Question Index: 18\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_19\n",
      "   Question Index: 19\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_20\n",
      "   Question Index: 20\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_21\n",
      "   Question Index: 21\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_22\n",
      "   Question Index: 22\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_23\n",
      "   Question Index: 23\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_24\n",
      "   Question Index: 24\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_25\n",
      "   Question Index: 25\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_26\n",
      "   Question Index: 26\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_27\n",
      "   Question Index: 27\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_28\n",
      "   Question Index: 28\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_29\n",
      "   Question Index: 29\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_31\n",
      "   Question Index: 31\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_32\n",
      "   Question Index: 32\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_33\n",
      "   Question Index: 33\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_34\n",
      "   Question Index: 34\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_35\n",
      "   Question Index: 35\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_36\n",
      "   Question Index: 36\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_37\n",
      "   Question Index: 37\n",
      "   Score: 10 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_38\n",
      "   Question Index: 38\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_40\n",
      "   Question Index: 40\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_41\n",
      "   Question Index: 41\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question ID: Question_42\n",
      "   Question Index: 42\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question ID: Question_0\n",
      "   Question Index: 0\n",
      "   Score: 8 (over 7!)\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question ID: Question_1\n",
      "   Question Index: 1\n",
      "   Score: 10 (over 7!)\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question ID: Question_2\n",
      "   Question Index: 2\n",
      "   Score: 9 (over 7!)\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "\n",
      "⚠️  TOTAL ISSUES FOUND: 37\n",
      "\n",
      "Summary by Model:\n",
      "  gpt-4.1-nano: 34 issues\n",
      "    - self_consistency_essay_n3, Q6: 8\n",
      "    - self_consistency_essay_n3, Q7: 9\n",
      "    - self_consistency_essay_n3, Q8: 8\n",
      "    - self_consistency_essay_n3, Q9: 9\n",
      "    - self_consistency_essay_n3, Q10: 8\n",
      "    - self_consistency_essay_n3, Q11: 8\n",
      "    - self_consistency_essay_n3, Q12: 8\n",
      "    - self_consistency_essay_n3, Q13: 8\n",
      "    - self_consistency_essay_n3, Q14: 9\n",
      "    - self_consistency_essay_n3, Q15: 8\n",
      "    - self_consistency_essay_n3, Q16: 8\n",
      "    - self_consistency_essay_n3, Q18: 8\n",
      "    - self_consistency_essay_n3, Q19: 8\n",
      "    - self_consistency_essay_n3, Q20: 8\n",
      "    - self_consistency_essay_n3, Q21: 8\n",
      "    - self_consistency_essay_n3, Q22: 8\n",
      "    - self_consistency_essay_n3, Q23: 8\n",
      "    - self_consistency_essay_n3, Q24: 8\n",
      "    - self_consistency_essay_n3, Q25: 8\n",
      "    - self_consistency_essay_n3, Q26: 9\n",
      "    - self_consistency_essay_n3, Q27: 9\n",
      "    - self_consistency_essay_n3, Q28: 8\n",
      "    - self_consistency_essay_n3, Q29: 8\n",
      "    - self_consistency_essay_n3, Q31: 8\n",
      "    - self_consistency_essay_n3, Q32: 9\n",
      "    - self_consistency_essay_n3, Q33: 8\n",
      "    - self_consistency_essay_n3, Q34: 9\n",
      "    - self_consistency_essay_n3, Q35: 9\n",
      "    - self_consistency_essay_n3, Q36: 8\n",
      "    - self_consistency_essay_n3, Q37: 10\n",
      "    - self_consistency_essay_n3, Q38: 8\n",
      "    - self_consistency_essay_n3, Q40: 8\n",
      "    - self_consistency_essay_n3, Q41: 9\n",
      "    - self_consistency_essay_n3, Q42: 8\n",
      "  deepseek-r1: 3 issues\n",
      "    - self_consistency_essay_n3, Q0: 8\n",
      "    - self_consistency_essay_n3, Q1: 10\n",
      "    - self_consistency_essay_n3, Q2: 9\n",
      "\n",
      "Saving issues to 'scoring_issues.csv'\n"
     ]
    }
   ],
   "source": [
    "def check_scores_over_7():\n",
    "    \"\"\"\n",
    "    Check all JSON files for any self_grade_score over 7 and flag them\n",
    "    \"\"\"\n",
    "    issues_found = []\n",
    "    \n",
    "    print(\"Checking for scores over 7...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for method in methods:\n",
    "        method_dir = f\"results/{method}\"\n",
    "        \n",
    "        if os.path.exists(method_dir):\n",
    "            json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "            \n",
    "            for filepath in json_files:\n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # Extract model name from filename\n",
    "                    filename = os.path.basename(filepath)\n",
    "                    model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "                    \n",
    "                    # Check each question in the file\n",
    "                    for idx, item in enumerate(data):\n",
    "                        if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                            score = item['self_grade_score']\n",
    "                            \n",
    "                            if score > 7:\n",
    "                                issue = {\n",
    "                                    'method': method,\n",
    "                                    'model': model_name,\n",
    "                                    'question_index': idx,\n",
    "                                    'score': score,\n",
    "                                    'file': filepath\n",
    "                                }\n",
    "                                \n",
    "                                # Try to get question text or ID for better identification\n",
    "                                question_id = item.get('question_id', item.get('id', f\"Question_{idx}\"))\n",
    "                                issue['question_id'] = question_id\n",
    "                                \n",
    "                                issues_found.append(issue)\n",
    "                                \n",
    "                                print(f\"🚨 ISSUE FOUND:\")\n",
    "                                print(f\"   Method: {method}\")\n",
    "                                print(f\"   Model: {model_name}\")\n",
    "                                print(f\"   Question ID: {question_id}\")\n",
    "                                print(f\"   Question Index: {idx}\")\n",
    "                                print(f\"   Score: {score} (over 7!)\")\n",
    "                                print(f\"   File: {os.path.basename(filepath)}\")\n",
    "                                print(\"-\" * 40)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error checking {filepath}: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    if issues_found:\n",
    "        print(f\"\\n⚠️  TOTAL ISSUES FOUND: {len(issues_found)}\")\n",
    "        print(\"\\nSummary by Model:\")\n",
    "        \n",
    "        # Group issues by model\n",
    "        from collections import defaultdict\n",
    "        issues_by_model = defaultdict(list)\n",
    "        for issue in issues_found:\n",
    "            issues_by_model[issue['model']].append(issue)\n",
    "        \n",
    "        for model, model_issues in issues_by_model.items():\n",
    "            print(f\"  {model}: {len(model_issues)} issues\")\n",
    "            for issue in model_issues:\n",
    "                print(f\"    - {issue['method']}, Q{issue['question_index']}: {issue['score']}\")\n",
    "        \n",
    "        # Create a DataFrame for easier analysis\n",
    "        issues_df = pd.DataFrame(issues_found)\n",
    "        print(f\"\\nSaving issues to 'scoring_issues.csv'\")\n",
    "        issues_df.to_csv('scoring_issues.csv', index=False)\n",
    "        \n",
    "        return issues_found\n",
    "    else:\n",
    "        print(\"✅ No scores over 7 found. All data looks good!\")\n",
    "        return []\n",
    "\n",
    "# Run the validation check\n",
    "issues = check_scores_over_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ff77620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing default_essay: Found 25 files\n",
      "  codestral-latest-official: 95/149 = 0.6376\n",
      "  gpt-4o: 124/149 = 0.8322\n",
      "  grok-3: 130/149 = 0.8725\n",
      "  groq-llama3.3-70b: 119/149 = 0.7987\n",
      "  claude-sonnet-4: 122/149 = 0.8188\n",
      "  claude-3.7-sonnet: 129/149 = 0.8658\n",
      "  groq-llama-guard-4: 0/149 = 0.0000\n",
      "  claude-3.5-haiku: 124/149 = 0.8322\n",
      "  gemini-2.5-pro: 137/149 = 0.9195\n",
      "  groq-llama-4-scout: 123/149 = 0.8255\n",
      "  o4-mini: 143/149 = 0.9597\n",
      "  gemini-2.5-flash: 132/149 = 0.8859\n",
      "  grok-3-mini-beta-high-effort: 130/149 = 0.8725\n",
      "  claude-opus-4: 113/149 = 0.7584\n",
      "  mistral-large-official: 110/149 = 0.7383\n",
      "  gpt-4.1-mini: 109/149 = 0.7315\n",
      "  groq-llama-4-maverick: 139/149 = 0.9329\n",
      "  deepseek-r1: 134/149 = 0.8993\n",
      "  gpt-4.1: 93/149 = 0.6242\n",
      "  grok-3-mini-beta-low-effort: 140/149 = 0.9396\n",
      "  gpt-4.1-nano: 97/149 = 0.6510\n",
      "  o3-mini: 141/149 = 0.9463\n",
      "  palmyra-fin-default: 110/149 = 0.7383\n",
      "  claude-3.5-sonnet: 133/149 = 0.8926\n",
      "  groq-llama3.1-8b-instant: 103/149 = 0.6913\n",
      "Processing self_consistency_essay_n3: Found 25 files\n",
      "  claude-3.7-sonnet: 141/149 = 0.9463\n",
      "  grok-3-mini-beta-low-effort: 133/149 = 0.8926\n",
      "  gemini-2.5-flash: 148/149 = 0.9933\n",
      "  groq-llama3.1-8b-instant: 102/149 = 0.6846\n",
      "  mistral-large-official: 124/149 = 0.8322\n",
      "  palmyra-fin-default: 119/149 = 0.7987\n",
      "  o3-mini: 144/149 = 0.9664\n",
      "  o4-mini: 148/149 = 0.9933\n",
      "  grok-3: 142/149 = 0.9530\n",
      "  gpt-4.1-nano: 315/149 = 2.1141\n",
      "  deepseek-r1: 159/149 = 1.0671\n",
      "  claude-sonnet-4: 139/149 = 0.9329\n",
      "  gemini-2.5-pro: 147/149 = 0.9866\n",
      "  gpt-4.1-mini: 130/149 = 0.8725\n",
      "  codestral-latest-official: 98/149 = 0.6577\n",
      "  gpt-4o: 126/149 = 0.8456\n",
      "  grok-3-mini-beta-high-effort: 140/149 = 0.9396\n",
      "  gpt-4.1: 109/149 = 0.7315\n",
      "  groq-llama3.3-70b: 122/149 = 0.8188\n",
      "  groq-llama-4-scout: 121/149 = 0.8121\n",
      "  claude-opus-4: 148/149 = 0.9933\n",
      "  claude-3.5-haiku: 134/149 = 0.8993\n",
      "  groq-llama-guard-4: 0/149 = 0.0000\n",
      "  claude-3.5-sonnet: 138/149 = 0.9262\n",
      "  groq-llama-4-maverick: 131/149 = 0.8792\n",
      "Processing self_consistency_essay_n5: Found 25 files\n",
      "  grok-3: 139/149 = 0.9329\n",
      "  gpt-4.1-nano: 111/149 = 0.7450\n",
      "  o3-mini: 144/149 = 0.9664\n",
      "  o4-mini: 146/149 = 0.9799\n",
      "  gemini-2.5-pro: 142/149 = 0.9530\n",
      "  gpt-4.1-mini: 127/149 = 0.8523\n",
      "  deepseek-r1: 137/149 = 0.9195\n",
      "  claude-sonnet-4: 140/149 = 0.9396\n",
      "  claude-3.7-sonnet: 144/149 = 0.9664\n",
      "  palmyra-fin-default: 121/149 = 0.8121\n",
      "  grok-3-mini-beta-low-effort: 136/149 = 0.9128\n",
      "  gemini-2.5-flash: 143/149 = 0.9597\n",
      "  groq-llama3.1-8b-instant: 111/149 = 0.7450\n",
      "  mistral-large-official: 122/149 = 0.8188\n",
      "  claude-opus-4: 144/149 = 0.9664\n",
      "  claude-3.5-haiku: 124/149 = 0.8322\n",
      "  groq-llama-4-scout: 125/149 = 0.8389\n",
      "  claude-3.5-sonnet: 138/149 = 0.9262\n",
      "  groq-llama-4-maverick: 138/149 = 0.9262\n",
      "  groq-llama-guard-4: 0/149 = 0.0000\n",
      "  gpt-4o: 132/149 = 0.8859\n",
      "  codestral-latest-official: 99/149 = 0.6644\n",
      "  gpt-4.1: 104/149 = 0.6980\n",
      "  groq-llama3.3-70b: 125/149 = 0.8389\n",
      "  grok-3-mini-beta-high-effort: 138/149 = 0.9262\n",
      "Processing self_discover_essay: Found 25 files\n",
      "  claude-opus-4: 140/149 = 0.9396\n",
      "  o3-mini: 146/149 = 0.9799\n",
      "  claude-3.5-haiku: 121/149 = 0.8121\n",
      "  gpt-4o: 111/149 = 0.7450\n",
      "  grok-3: 135/149 = 0.9060\n",
      "  groq-llama-guard-4: 0/149 = 0.0000\n",
      "  o4-mini: 144/149 = 0.9664\n",
      "  groq-llama-4-maverick: 128/149 = 0.8591\n",
      "  claude-3.7-sonnet: 137/149 = 0.9195\n",
      "  grok-3-mini-beta-low-effort: 118/149 = 0.7919\n",
      "  palmyra-fin-default: 115/149 = 0.7718\n",
      "  groq-llama-4-scout: 112/149 = 0.7517\n",
      "  gpt-4.1: 114/149 = 0.7651\n",
      "  claude-sonnet-4: 138/149 = 0.9262\n",
      "  grok-3-mini-beta-high-effort: 109/149 = 0.7315\n",
      "  gpt-4.1-mini: 116/149 = 0.7785\n",
      "  mistral-large-official: 109/149 = 0.7315\n",
      "  groq-llama3.3-70b: 113/149 = 0.7584\n",
      "  gemini-2.5-flash: 140/149 = 0.9396\n",
      "  gemini-2.5-pro: 142/149 = 0.9530\n",
      "  claude-3.5-sonnet: 139/149 = 0.9329\n",
      "  deepseek-r1: 131/149 = 0.8792\n",
      "  codestral-latest-official: 105/149 = 0.7047\n",
      "  groq-llama3.1-8b-instant: 105/149 = 0.7047\n",
      "  gpt-4.1-nano: 87/149 = 0.5839\n"
     ]
    }
   ],
   "source": [
    "# Process each method directory\n",
    "for method in methods:\n",
    "    method_dir = f\"results/{method}\"\n",
    "    \n",
    "    if os.path.exists(method_dir):\n",
    "        # Find all JSON files in the directory\n",
    "        json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "        \n",
    "        print(f\"Processing {method}: Found {len(json_files)} files\")\n",
    "        \n",
    "        for filepath in json_files:\n",
    "            model_name, total_score, num_questions, normalized_score = process_json_file(filepath)\n",
    "            \n",
    "            if model_name:\n",
    "                # Initialize model entry if not exists\n",
    "                if model_name not in results_data:\n",
    "                    results_data[model_name] = {}\n",
    "                \n",
    "                # Store the normalized score for this method\n",
    "                results_data[model_name][method] = normalized_score\n",
    "                \n",
    "                print(f\"  {model_name}: {total_score}/{149} = {normalized_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"Directory {method_dir} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39f5fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results Table:\n",
      "================================================================================\n",
      "                              default_essay  self_consistency_essay_n3  \\\n",
      "claude-3.5-haiku                     0.8322                     0.8993   \n",
      "claude-3.5-sonnet                    0.8926                     0.9262   \n",
      "claude-3.7-sonnet                    0.8658                     0.9463   \n",
      "claude-opus-4                        0.7584                     0.9933   \n",
      "claude-sonnet-4                      0.8188                     0.9329   \n",
      "codestral-latest-official            0.6376                     0.6577   \n",
      "deepseek-r1                          0.8993                     1.0671   \n",
      "gemini-2.5-flash                     0.8859                     0.9933   \n",
      "gemini-2.5-pro                       0.9195                     0.9866   \n",
      "gpt-4.1                              0.6242                     0.7315   \n",
      "gpt-4.1-mini                         0.7315                     0.8725   \n",
      "gpt-4.1-nano                         0.6510                     2.1141   \n",
      "gpt-4o                               0.8322                     0.8456   \n",
      "grok-3                               0.8725                     0.9530   \n",
      "grok-3-mini-beta-high-effort         0.8725                     0.9396   \n",
      "grok-3-mini-beta-low-effort          0.9396                     0.8926   \n",
      "groq-llama-4-maverick                0.9329                     0.8792   \n",
      "groq-llama-4-scout                   0.8255                     0.8121   \n",
      "groq-llama-guard-4                   0.0000                     0.0000   \n",
      "groq-llama3.1-8b-instant             0.6913                     0.6846   \n",
      "groq-llama3.3-70b                    0.7987                     0.8188   \n",
      "mistral-large-official               0.7383                     0.8322   \n",
      "o3-mini                              0.9463                     0.9664   \n",
      "o4-mini                              0.9597                     0.9933   \n",
      "palmyra-fin-default                  0.7383                     0.7987   \n",
      "\n",
      "                              self_consistency_essay_n5  self_discover_essay  \n",
      "claude-3.5-haiku                                 0.8322               0.8121  \n",
      "claude-3.5-sonnet                                0.9262               0.9329  \n",
      "claude-3.7-sonnet                                0.9664               0.9195  \n",
      "claude-opus-4                                    0.9664               0.9396  \n",
      "claude-sonnet-4                                  0.9396               0.9262  \n",
      "codestral-latest-official                        0.6644               0.7047  \n",
      "deepseek-r1                                      0.9195               0.8792  \n",
      "gemini-2.5-flash                                 0.9597               0.9396  \n",
      "gemini-2.5-pro                                   0.9530               0.9530  \n",
      "gpt-4.1                                          0.6980               0.7651  \n",
      "gpt-4.1-mini                                     0.8523               0.7785  \n",
      "gpt-4.1-nano                                     0.7450               0.5839  \n",
      "gpt-4o                                           0.8859               0.7450  \n",
      "grok-3                                           0.9329               0.9060  \n",
      "grok-3-mini-beta-high-effort                     0.9262               0.7315  \n",
      "grok-3-mini-beta-low-effort                      0.9128               0.7919  \n",
      "groq-llama-4-maverick                            0.9262               0.8591  \n",
      "groq-llama-4-scout                               0.8389               0.7517  \n",
      "groq-llama-guard-4                               0.0000               0.0000  \n",
      "groq-llama3.1-8b-instant                         0.7450               0.7047  \n",
      "groq-llama3.3-70b                                0.8389               0.7584  \n",
      "mistral-large-official                           0.8188               0.7315  \n",
      "o3-mini                                          0.9664               0.9799  \n",
      "o4-mini                                          0.9799               0.9664  \n",
      "palmyra-fin-default                              0.8121               0.7718  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(results_data, orient='index')\n",
    "\n",
    "# Reorder columns to match the specified order\n",
    "df = df.reindex(columns=methods)\n",
    "\n",
    "# Fill NaN values with 0 (in case some models don't have results for all methods)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Sort by model name for better readability\n",
    "df = df.sort_index()\n",
    "\n",
    "print(\"Final Results Table:\")\n",
    "print(\"=\" * 80)\n",
    "print(df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

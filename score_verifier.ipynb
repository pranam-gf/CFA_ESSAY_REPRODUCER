{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b4c17a",
   "metadata": {},
   "source": [
    "### Load the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2924bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the methods/processes\n",
    "methods = ['default_essay','self_consistency_essay_n3', 'self_consistency_essay_n5', 'self_discover_essay']\n",
    "\n",
    "# Create a dictionary to store all results\n",
    "results_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f42c2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded grading details successfully: 43 questions\n",
      "📊 Total possible points across all questions: 149\n",
      "📈 Max scores per question: [6, 2, 2, 5, 2, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 5, 5, 4, 3, 7, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Load the grading details file and extract max scores in order\n",
    "# We assume the questions are in the same order in both files\n",
    "try:\n",
    "    with open('data/answer_grading_details.json', 'r') as f:\n",
    "        grading_details_list = json.load(f)\n",
    "    \n",
    "    # Extract max scores in order - assuming same order as evaluated results\n",
    "    max_scores_per_question = [item['max_score'] for item in grading_details_list]\n",
    "    total_possible_points = sum(max_scores_per_question)\n",
    "    \n",
    "    print(f\"✅ Loaded grading details successfully: {len(max_scores_per_question)} questions\")\n",
    "    print(f\"📊 Total possible points across all questions: {total_possible_points}\")\n",
    "    print(f\"📈 Max scores per question: {max_scores_per_question}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading grading details: {e}\")\n",
    "    max_scores_per_question = []\n",
    "    total_possible_points = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75a9984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single JSON file and calculate the aggregate score using actual max scores\n",
    "    Assumes questions are in the same order as the grading details file\n",
    "    Returns: (model_name, total_score, num_questions, normalized_score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract model name from filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "        \n",
    "        # Calculate total self_grade_score\n",
    "        total_score = 0\n",
    "        num_questions_with_scores = 0\n",
    "        \n",
    "        for idx, item in enumerate(data):\n",
    "            if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                total_score += item['self_grade_score']\n",
    "                num_questions_with_scores += 1\n",
    "        \n",
    "        # Calculate normalized score using the predetermined total possible points\n",
    "        # We assume all questions should have scores, so we use the full total_possible_points\n",
    "        normalized_score = total_score / total_possible_points if total_possible_points > 0 else 0\n",
    "        \n",
    "        return model_name, total_score, num_questions_with_scores, normalized_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a5aa5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for invalid scores (> max_score or < 0)...\n",
      "============================================================\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 6\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: Using the Grinold-Kroner Model, calculate the expected equity market returns of Island Nation 1.\n",
      "(Sh...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 7\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Discuss the purchasing power parity theory's ability to forecast long-term and short-term movements ...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 8\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Identify which hedge fund strategy Leon should view as least suitable for meeting Rhino's Investment...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 9\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Identify which hedge fund strategy Leon should view as most suitable for meeting Rhino's Investment ...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 10\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: In a subsequent meeting with Rhino's Investment Committee, Leon presents her recommendation regardin...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 11\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: |  Discuss three key risks associated with investing in distressed debt, particularly in the context...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 12\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Explain the process of a distressed debt exchange and its benefits to both the issuer and the invest...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 13\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Discuss three key issues in the due diligence process in special situations of investing, particular...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 14\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Analyze three potential positive outcomes for Riverstone Capital if they successfully restructure St...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 15\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Assuming the models are correct, indicate whether Rashid and his team should most likely increase po...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 16\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: In response to Ibrahim's comment to his supervisor about portfolio structures during a flattening yi...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 17\n",
      "   Issue: OVER MAX (score: 7, max: 4)\n",
      "   Question: # Calculate the convexity of the Israeli Government bonds.\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 18\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Based on a proposed base fee of $0.25 \\%$ and performance sharing of $16 \\%$ with a maximum annual f...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 19\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: If a hedge fund managed by OAM earns an active return of $2.75 \\%$, calculate the performance-based ...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 20\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Given a new symmetrical fee structure, explain how OAM's management might adjust their strategy to b...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 21\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Analyze the potential impact of including a high-water mark and maximum fee cap in the fee schedule,...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 22\n",
      "   Issue: OVER MAX (score: 8, max: 5)\n",
      "   Question: State the trading algorithm most likely described by Yuan.\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 23\n",
      "   Issue: OVER MAX (score: 8, max: 5)\n",
      "   Question: Next, Fox meets with Jared DeLeto, a Senior Analyst at the firm. DeLeto mentions he graduated from t...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 24\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: Next, Fox is shown to the office of Mae Figueroa, the firm's head trader, with whom he will lunch du...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 25\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Finally, Fox meets with the firm's charismatic founder and CEO, Lance Cannon. Cannon describes that ...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 26\n",
      "   Issue: OVER MAX (score: 9, max: 7)\n",
      "   Question: Choose whether the investor should be long or short a forward contract for the grain trade. Describe...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 27\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Next, Theun meets with his supervisor and mentee to discuss the portfolio of a wealthy individual cl...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 28\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: Theun has discussed the strategy above with his supervisor, and they agree that with the current bev...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 29\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: Next, Theun meets with Valdomir Etov, a client tasked the firm with trading a high-leverage account....\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 30\n",
      "   Issue: OVER MAX (score: 7, max: 4)\n",
      "   Question: Finally, Theun looks at the Clear Lake Regional Network (ticker: CLRN) October 20XX $\\$ 23$ call opt...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 31\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: State whether you agree or disagree with each statement made by the supervisor. If you disagree, jus...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 32\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: | Firm | Harvison and Marwick, PLLC |\n",
      "| :-- | :-- |\n",
      "| Composite | North American Precious Metals |\n",
      "|...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 33\n",
      "   Issue: OVER MAX (score: 8, max: 4)\n",
      "   Question: Wilkerson's supervisor gives her a partial year accounting of the cash flows and composite values of...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 34\n",
      "   Issue: OVER MAX (score: 9, max: 4)\n",
      "   Question: Finally, Wilkerson gets her first chance to give her input on a live project the firm is working on....\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 35\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Calculate the Distributed to Paid-In (DPI) multiple for Apex Capital's private equity fund at the en...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 36\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Calculate the Residual Value to Paid-In (RVPI) multiple for Apex Capital's private equity fund at th...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 37\n",
      "   Issue: OVER MAX (score: 10, max: 3)\n",
      "   Question: Calculate the Total Value to Paid-In (TVPI) multiple for Apex Capital's private equity fund at the e...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 38\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Calculate the amount of carried interest Apex Capital would earn at the end of year 10.\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 39\n",
      "   Issue: OVER MAX (score: 7, max: 3)\n",
      "   Question: Identify and discuss the critical challenges faced by the Patel family due to their multijurisdictio...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 40\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Recommend strategies for managing the Patel family's investments considering their multijurisdiction...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 41\n",
      "   Issue: OVER MAX (score: 9, max: 3)\n",
      "   Question: Explain one benefit, one potential drawback, and a long-term consideration of renouncing citizenship...\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: gpt-4.1-nano\n",
      "   Question Index: 42\n",
      "   Issue: OVER MAX (score: 8, max: 3)\n",
      "   Question: Evaluate the role of double taxation treaties in the Patel family's financial planning.\n",
      "   File: evaluated_results_gpt-4.1-nano__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question Index: 0\n",
      "   Issue: OVER MAX (score: 8, max: 6)\n",
      "   Question: Calculate the annualized post-liquidation return over the 5 years for the Nilsson portfolio.\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question Index: 1\n",
      "   Issue: OVER MAX (score: 10, max: 2)\n",
      "   Question: The Nilssons are happy to see the work done by Klinberg, and at their next meeting, they discuss the...\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "🚨 ISSUE FOUND:\n",
      "   Method: self_consistency_essay_n3\n",
      "   Model: deepseek-r1\n",
      "   Question Index: 2\n",
      "   Issue: OVER MAX (score: 9, max: 2)\n",
      "   Question: Klingberg knows that his clients are tax-sensitive investors and wants to show that he is doing ever...\n",
      "   File: evaluated_results_deepseek-r1__self_consistency_essay_n3.json\n",
      "----------------------------------------\n",
      "\n",
      "⚠️  TOTAL ISSUES FOUND: 40\n",
      "   - Scores over maximum: 40\n",
      "   - Scores below minimum (0): 0\n",
      "\n",
      "Summary by Model:\n",
      "  gpt-4.1-nano: 37 issues\n",
      "    - self_consistency_essay_n3, Q6: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q7: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q8: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q9: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q10: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q11: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q12: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q13: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q14: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q15: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q16: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q17: OVER MAX (score: 7, max: 4)\n",
      "    - self_consistency_essay_n3, Q18: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q19: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q20: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q21: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q22: OVER MAX (score: 8, max: 5)\n",
      "    - self_consistency_essay_n3, Q23: OVER MAX (score: 8, max: 5)\n",
      "    - self_consistency_essay_n3, Q24: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q25: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q26: OVER MAX (score: 9, max: 7)\n",
      "    - self_consistency_essay_n3, Q27: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q28: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q29: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q30: OVER MAX (score: 7, max: 4)\n",
      "    - self_consistency_essay_n3, Q31: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q32: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q33: OVER MAX (score: 8, max: 4)\n",
      "    - self_consistency_essay_n3, Q34: OVER MAX (score: 9, max: 4)\n",
      "    - self_consistency_essay_n3, Q35: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q36: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q37: OVER MAX (score: 10, max: 3)\n",
      "    - self_consistency_essay_n3, Q38: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q39: OVER MAX (score: 7, max: 3)\n",
      "    - self_consistency_essay_n3, Q40: OVER MAX (score: 8, max: 3)\n",
      "    - self_consistency_essay_n3, Q41: OVER MAX (score: 9, max: 3)\n",
      "    - self_consistency_essay_n3, Q42: OVER MAX (score: 8, max: 3)\n",
      "  deepseek-r1: 3 issues\n",
      "    - self_consistency_essay_n3, Q0: OVER MAX (score: 8, max: 6)\n",
      "    - self_consistency_essay_n3, Q1: OVER MAX (score: 10, max: 2)\n",
      "    - self_consistency_essay_n3, Q2: OVER MAX (score: 9, max: 2)\n",
      "\n",
      "Summary by Method:\n",
      "  self_consistency_essay_n3: 40 issues\n",
      "\n",
      "Saving issues to 'scoring_issues.csv'\n"
     ]
    }
   ],
   "source": [
    "def check_invalid_scores():\n",
    "    \"\"\"\n",
    "    Check all JSON files for any self_grade_score that exceeds the max score for that question\n",
    "    or is below 0 (minimum score)\n",
    "    \"\"\"\n",
    "    issues_found = []\n",
    "    \n",
    "    print(\"Checking for invalid scores (> max_score or < 0)...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for method in methods:\n",
    "        method_dir = f\"results/{method}\"\n",
    "        \n",
    "        if os.path.exists(method_dir):\n",
    "            json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "            \n",
    "            for filepath in json_files:\n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # Extract model name from filename\n",
    "                    filename = os.path.basename(filepath)\n",
    "                    model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "                    \n",
    "                    # Check each question in the file\n",
    "                    for idx, item in enumerate(data):\n",
    "                        if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                            score = item['self_grade_score']\n",
    "                            \n",
    "                            # Get the max score for this question (assuming same order)\n",
    "                            if idx < len(max_scores_per_question):\n",
    "                                max_score = max_scores_per_question[idx]\n",
    "                            else:\n",
    "                                max_score = 7  # Fallback if index out of range\n",
    "                                print(f\"⚠️  Question index {idx} out of range, using default max_score=7\")\n",
    "                            \n",
    "                            # Check for invalid scores\n",
    "                            is_invalid = False\n",
    "                            issue_type = \"\"\n",
    "                            \n",
    "                            if score > max_score:\n",
    "                                is_invalid = True\n",
    "                                issue_type = f\"OVER MAX (score: {score}, max: {max_score})\"\n",
    "                            elif score < 0:\n",
    "                                is_invalid = True\n",
    "                                issue_type = f\"BELOW MIN (score: {score}, min: 0)\"\n",
    "                            \n",
    "                            if is_invalid:\n",
    "                                issue = {\n",
    "                                    'method': method,\n",
    "                                    'model': model_name,\n",
    "                                    'question_index': idx,\n",
    "                                    'score': score,\n",
    "                                    'max_score': max_score,\n",
    "                                    'issue_type': issue_type,\n",
    "                                    'file': filepath\n",
    "                                }\n",
    "                                \n",
    "                                # Try to get question text for better identification\n",
    "                                question_text = item.get('question', f\"Question_{idx}\")\n",
    "                                question_preview = question_text[:100] + \"...\" if len(question_text) > 100 else question_text\n",
    "                                issue['question_preview'] = question_preview\n",
    "                                \n",
    "                                issues_found.append(issue)\n",
    "                                \n",
    "                                print(f\"🚨 ISSUE FOUND:\")\n",
    "                                print(f\"   Method: {method}\")\n",
    "                                print(f\"   Model: {model_name}\")\n",
    "                                print(f\"   Question Index: {idx}\")\n",
    "                                print(f\"   Issue: {issue_type}\")\n",
    "                                print(f\"   Question: {question_preview}\")\n",
    "                                print(f\"   File: {os.path.basename(filepath)}\")\n",
    "                                print(\"-\" * 40)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error checking {filepath}: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    if issues_found:\n",
    "        print(f\"\\n⚠️  TOTAL ISSUES FOUND: {len(issues_found)}\")\n",
    "        \n",
    "        # Count by issue type\n",
    "        over_max_count = sum(1 for issue in issues_found if \"OVER MAX\" in issue['issue_type'])\n",
    "        below_min_count = sum(1 for issue in issues_found if \"BELOW MIN\" in issue['issue_type'])\n",
    "        \n",
    "        print(f\"   - Scores over maximum: {over_max_count}\")\n",
    "        print(f\"   - Scores below minimum (0): {below_min_count}\")\n",
    "        \n",
    "        print(\"\\nSummary by Model:\")\n",
    "        \n",
    "        # Group issues by model\n",
    "        from collections import defaultdict\n",
    "        issues_by_model = defaultdict(list)\n",
    "        for issue in issues_found:\n",
    "            issues_by_model[issue['model']].append(issue)\n",
    "        \n",
    "        for model, model_issues in issues_by_model.items():\n",
    "            print(f\"  {model}: {len(model_issues)} issues\")\n",
    "            for issue in model_issues:\n",
    "                print(f\"    - {issue['method']}, Q{issue['question_index']}: {issue['issue_type']}\")\n",
    "        \n",
    "        print(\"\\nSummary by Method:\")\n",
    "        issues_by_method = defaultdict(list)\n",
    "        for issue in issues_found:\n",
    "            issues_by_method[issue['method']].append(issue)\n",
    "        \n",
    "        for method, method_issues in issues_by_method.items():\n",
    "            print(f\"  {method}: {len(method_issues)} issues\")\n",
    "        \n",
    "        # Create a DataFrame for easier analysis\n",
    "        issues_df = pd.DataFrame(issues_found)\n",
    "        print(f\"\\nSaving issues to 'scoring_issues.csv'\")\n",
    "        issues_df.to_csv('scoring_issues.csv', index=False)\n",
    "        \n",
    "        return issues_found\n",
    "    else:\n",
    "        print(\"✅ No invalid scores found. All scores are within valid ranges!\")\n",
    "        return []\n",
    "\n",
    "# Run the validation check\n",
    "issues = check_invalid_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ff77620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing default_essay: Found 25 files\n",
      "  codestral-latest-official: 95/149 = 0.6376 (43 questions)\n",
      "  gpt-4o: 124/149 = 0.8322 (43 questions)\n",
      "  grok-3: 130/149 = 0.8725 (43 questions)\n",
      "  groq-llama3.3-70b: 119/149 = 0.7987 (43 questions)\n",
      "  claude-sonnet-4: 122/149 = 0.8188 (43 questions)\n",
      "  claude-3.7-sonnet: 129/149 = 0.8658 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  claude-3.5-haiku: 124/149 = 0.8322 (43 questions)\n",
      "  gemini-2.5-pro: 137/149 = 0.9195 (43 questions)\n",
      "  groq-llama-4-scout: 123/149 = 0.8255 (43 questions)\n",
      "  o4-mini: 143/149 = 0.9597 (43 questions)\n",
      "  gemini-2.5-flash: 132/149 = 0.8859 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 130/149 = 0.8725 (41 questions)\n",
      "  claude-opus-4: 113/149 = 0.7584 (43 questions)\n",
      "  mistral-large-official: 110/149 = 0.7383 (43 questions)\n",
      "  gpt-4.1-mini: 109/149 = 0.7315 (43 questions)\n",
      "  groq-llama-4-maverick: 139/149 = 0.9329 (43 questions)\n",
      "  deepseek-r1: 134/149 = 0.8993 (43 questions)\n",
      "  gpt-4.1: 93/149 = 0.6242 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 140/149 = 0.9396 (43 questions)\n",
      "  gpt-4.1-nano: 97/149 = 0.6510 (43 questions)\n",
      "  o3-mini: 141/149 = 0.9463 (43 questions)\n",
      "  palmyra-fin-default: 110/149 = 0.7383 (43 questions)\n",
      "  claude-3.5-sonnet: 133/149 = 0.8926 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 103/149 = 0.6913 (43 questions)\n",
      "Processing self_consistency_essay_n3: Found 25 files\n",
      "  claude-3.7-sonnet: 141/149 = 0.9463 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 133/149 = 0.8926 (43 questions)\n",
      "  gemini-2.5-flash: 148/149 = 0.9933 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 102/149 = 0.6846 (43 questions)\n",
      "  mistral-large-official: 124/149 = 0.8322 (43 questions)\n",
      "  palmyra-fin-default: 119/149 = 0.7987 (43 questions)\n",
      "  o3-mini: 144/149 = 0.9664 (43 questions)\n",
      "  o4-mini: 148/149 = 0.9933 (43 questions)\n",
      "  grok-3: 142/149 = 0.9530 (43 questions)\n",
      "  gpt-4.1-nano: 315/149 = 2.1141 (43 questions)\n",
      "  deepseek-r1: 159/149 = 1.0671 (43 questions)\n",
      "  claude-sonnet-4: 139/149 = 0.9329 (43 questions)\n",
      "  gemini-2.5-pro: 147/149 = 0.9866 (43 questions)\n",
      "  gpt-4.1-mini: 130/149 = 0.8725 (43 questions)\n",
      "  codestral-latest-official: 98/149 = 0.6577 (43 questions)\n",
      "  gpt-4o: 126/149 = 0.8456 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 140/149 = 0.9396 (43 questions)\n",
      "  gpt-4.1: 109/149 = 0.7315 (43 questions)\n",
      "  groq-llama3.3-70b: 122/149 = 0.8188 (43 questions)\n",
      "  groq-llama-4-scout: 121/149 = 0.8121 (43 questions)\n",
      "  claude-opus-4: 148/149 = 0.9933 (43 questions)\n",
      "  claude-3.5-haiku: 134/149 = 0.8993 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  claude-3.5-sonnet: 138/149 = 0.9262 (43 questions)\n",
      "  groq-llama-4-maverick: 131/149 = 0.8792 (43 questions)\n",
      "Processing self_consistency_essay_n5: Found 25 files\n",
      "  grok-3: 139/149 = 0.9329 (43 questions)\n",
      "  gpt-4.1-nano: 111/149 = 0.7450 (43 questions)\n",
      "  o3-mini: 144/149 = 0.9664 (43 questions)\n",
      "  o4-mini: 146/149 = 0.9799 (43 questions)\n",
      "  gemini-2.5-pro: 142/149 = 0.9530 (43 questions)\n",
      "  gpt-4.1-mini: 127/149 = 0.8523 (43 questions)\n",
      "  deepseek-r1: 137/149 = 0.9195 (43 questions)\n",
      "  claude-sonnet-4: 140/149 = 0.9396 (43 questions)\n",
      "  claude-3.7-sonnet: 144/149 = 0.9664 (43 questions)\n",
      "  palmyra-fin-default: 121/149 = 0.8121 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 136/149 = 0.9128 (43 questions)\n",
      "  gemini-2.5-flash: 143/149 = 0.9597 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 111/149 = 0.7450 (43 questions)\n",
      "  mistral-large-official: 122/149 = 0.8188 (43 questions)\n",
      "  claude-opus-4: 144/149 = 0.9664 (43 questions)\n",
      "  claude-3.5-haiku: 124/149 = 0.8322 (43 questions)\n",
      "  groq-llama-4-scout: 125/149 = 0.8389 (43 questions)\n",
      "  claude-3.5-sonnet: 138/149 = 0.9262 (43 questions)\n",
      "  groq-llama-4-maverick: 138/149 = 0.9262 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  gpt-4o: 132/149 = 0.8859 (43 questions)\n",
      "  codestral-latest-official: 99/149 = 0.6644 (43 questions)\n",
      "  gpt-4.1: 104/149 = 0.6980 (43 questions)\n",
      "  groq-llama3.3-70b: 125/149 = 0.8389 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 138/149 = 0.9262 (43 questions)\n",
      "Processing self_discover_essay: Found 25 files\n",
      "  claude-opus-4: 140/149 = 0.9396 (43 questions)\n",
      "  o3-mini: 146/149 = 0.9799 (43 questions)\n",
      "  claude-3.5-haiku: 121/149 = 0.8121 (43 questions)\n",
      "  gpt-4o: 111/149 = 0.7450 (43 questions)\n",
      "  grok-3: 135/149 = 0.9060 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  o4-mini: 144/149 = 0.9664 (43 questions)\n",
      "  groq-llama-4-maverick: 128/149 = 0.8591 (43 questions)\n",
      "  claude-3.7-sonnet: 137/149 = 0.9195 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 118/149 = 0.7919 (43 questions)\n",
      "  palmyra-fin-default: 115/149 = 0.7718 (43 questions)\n",
      "  groq-llama-4-scout: 112/149 = 0.7517 (43 questions)\n",
      "  gpt-4.1: 114/149 = 0.7651 (43 questions)\n",
      "  claude-sonnet-4: 138/149 = 0.9262 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 109/149 = 0.7315 (42 questions)\n",
      "  gpt-4.1-mini: 116/149 = 0.7785 (43 questions)\n",
      "  mistral-large-official: 109/149 = 0.7315 (43 questions)\n",
      "  groq-llama3.3-70b: 113/149 = 0.7584 (43 questions)\n",
      "  gemini-2.5-flash: 140/149 = 0.9396 (43 questions)\n",
      "  gemini-2.5-pro: 142/149 = 0.9530 (43 questions)\n",
      "  claude-3.5-sonnet: 139/149 = 0.9329 (43 questions)\n",
      "  deepseek-r1: 131/149 = 0.8792 (43 questions)\n",
      "  codestral-latest-official: 105/149 = 0.7047 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 105/149 = 0.7047 (43 questions)\n",
      "  gpt-4.1-nano: 87/149 = 0.5839 (43 questions)\n"
     ]
    }
   ],
   "source": [
    "# Process each method directory\n",
    "for method in methods:\n",
    "    method_dir = f\"results/{method}\"\n",
    "    \n",
    "    if os.path.exists(method_dir):\n",
    "        # Find all JSON files in the directory\n",
    "        json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "        \n",
    "        print(f\"Processing {method}: Found {len(json_files)} files\")\n",
    "        \n",
    "        for filepath in json_files:\n",
    "            model_name, total_score, num_questions, normalized_score = process_json_file(filepath)\n",
    "            \n",
    "            if model_name:\n",
    "                # Initialize model entry if not exists\n",
    "                if model_name not in results_data:\n",
    "                    results_data[model_name] = {}\n",
    "                \n",
    "                # Store the normalized score for this method\n",
    "                results_data[model_name][method] = normalized_score\n",
    "                \n",
    "                print(f\"  {model_name}: {total_score}/{total_possible_points} = {normalized_score:.4f} ({num_questions} questions)\")\n",
    "    else:\n",
    "        print(f\"Directory {method_dir} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39f5fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results Table:\n",
      "================================================================================\n",
      "                              default_essay  self_consistency_essay_n3  \\\n",
      "claude-3.5-haiku                     0.8322                     0.8993   \n",
      "claude-3.5-sonnet                    0.8926                     0.9262   \n",
      "claude-3.7-sonnet                    0.8658                     0.9463   \n",
      "claude-opus-4                        0.7584                     0.9933   \n",
      "claude-sonnet-4                      0.8188                     0.9329   \n",
      "codestral-latest-official            0.6376                     0.6577   \n",
      "deepseek-r1                          0.8993                     1.0671   \n",
      "gemini-2.5-flash                     0.8859                     0.9933   \n",
      "gemini-2.5-pro                       0.9195                     0.9866   \n",
      "gpt-4.1                              0.6242                     0.7315   \n",
      "gpt-4.1-mini                         0.7315                     0.8725   \n",
      "gpt-4.1-nano                         0.6510                     2.1141   \n",
      "gpt-4o                               0.8322                     0.8456   \n",
      "grok-3                               0.8725                     0.9530   \n",
      "grok-3-mini-beta-high-effort         0.8725                     0.9396   \n",
      "grok-3-mini-beta-low-effort          0.9396                     0.8926   \n",
      "groq-llama-4-maverick                0.9329                     0.8792   \n",
      "groq-llama-4-scout                   0.8255                     0.8121   \n",
      "groq-llama-guard-4                   0.0000                     0.0000   \n",
      "groq-llama3.1-8b-instant             0.6913                     0.6846   \n",
      "groq-llama3.3-70b                    0.7987                     0.8188   \n",
      "mistral-large-official               0.7383                     0.8322   \n",
      "o3-mini                              0.9463                     0.9664   \n",
      "o4-mini                              0.9597                     0.9933   \n",
      "palmyra-fin-default                  0.7383                     0.7987   \n",
      "\n",
      "                              self_consistency_essay_n5  self_discover_essay  \n",
      "claude-3.5-haiku                                 0.8322               0.8121  \n",
      "claude-3.5-sonnet                                0.9262               0.9329  \n",
      "claude-3.7-sonnet                                0.9664               0.9195  \n",
      "claude-opus-4                                    0.9664               0.9396  \n",
      "claude-sonnet-4                                  0.9396               0.9262  \n",
      "codestral-latest-official                        0.6644               0.7047  \n",
      "deepseek-r1                                      0.9195               0.8792  \n",
      "gemini-2.5-flash                                 0.9597               0.9396  \n",
      "gemini-2.5-pro                                   0.9530               0.9530  \n",
      "gpt-4.1                                          0.6980               0.7651  \n",
      "gpt-4.1-mini                                     0.8523               0.7785  \n",
      "gpt-4.1-nano                                     0.7450               0.5839  \n",
      "gpt-4o                                           0.8859               0.7450  \n",
      "grok-3                                           0.9329               0.9060  \n",
      "grok-3-mini-beta-high-effort                     0.9262               0.7315  \n",
      "grok-3-mini-beta-low-effort                      0.9128               0.7919  \n",
      "groq-llama-4-maverick                            0.9262               0.8591  \n",
      "groq-llama-4-scout                               0.8389               0.7517  \n",
      "groq-llama-guard-4                               0.0000               0.0000  \n",
      "groq-llama3.1-8b-instant                         0.7450               0.7047  \n",
      "groq-llama3.3-70b                                0.8389               0.7584  \n",
      "mistral-large-official                           0.8188               0.7315  \n",
      "o3-mini                                          0.9664               0.9799  \n",
      "o4-mini                                          0.9799               0.9664  \n",
      "palmyra-fin-default                              0.8121               0.7718  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(results_data, orient='index')\n",
    "\n",
    "# Reorder columns to match the specified order\n",
    "df = df.reindex(columns=methods)\n",
    "\n",
    "# Fill NaN values with 0 (in case some models don't have results for all methods)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Sort by model name for better readability\n",
    "df = df.sort_index()\n",
    "\n",
    "print(\"Final Results Table:\")\n",
    "print(\"=\" * 80)\n",
    "print(df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

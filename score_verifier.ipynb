{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b4c17a",
   "metadata": {},
   "source": [
    "### Load the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2924bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the methods/processes\n",
    "methods = ['default_essay','self_consistency_essay_n3', 'self_consistency_essay_n5', 'self_discover_essay']\n",
    "\n",
    "# Create a dictionary to store all results\n",
    "results_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f42c2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded grading details successfully: 43 questions\n",
      "üìä Total possible points across all questions: 149\n",
      "üìà Max scores per question: [6, 2, 2, 5, 2, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 5, 5, 4, 3, 7, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Load the grading details file and extract max scores in order\n",
    "# We assume the questions are in the same order in both files\n",
    "try:\n",
    "    with open('data/answer_grading_details.json', 'r') as f:\n",
    "        grading_details_list = json.load(f)\n",
    "    \n",
    "    # Extract max scores in order - assuming same order as evaluated results\n",
    "    max_scores_per_question = [item['max_score'] for item in grading_details_list]\n",
    "    total_possible_points = sum(max_scores_per_question)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded grading details successfully: {len(max_scores_per_question)} questions\")\n",
    "    print(f\"üìä Total possible points across all questions: {total_possible_points}\")\n",
    "    print(f\"üìà Max scores per question: {max_scores_per_question}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading grading details: {e}\")\n",
    "    max_scores_per_question = []\n",
    "    total_possible_points = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75a9984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single JSON file and calculate the aggregate score using actual max scores\n",
    "    Assumes questions are in the same order as the grading details file\n",
    "    Returns: (model_name, total_score, num_questions, normalized_score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract model name from filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "        \n",
    "        # Calculate total self_grade_score\n",
    "        total_score = 0\n",
    "        num_questions_with_scores = 0\n",
    "        \n",
    "        for idx, item in enumerate(data):\n",
    "            if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                total_score += item['self_grade_score']\n",
    "                num_questions_with_scores += 1\n",
    "        \n",
    "        # Calculate normalized score using the predetermined total possible points\n",
    "        # We assume all questions should have scores, so we use the full total_possible_points\n",
    "        normalized_score = total_score / total_possible_points if total_possible_points > 0 else 0\n",
    "        \n",
    "        return model_name, total_score, num_questions_with_scores, normalized_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a5aa5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for invalid scores (> max_score or < 0)...\n",
      "============================================================\n",
      "‚úÖ No invalid scores found. All scores are within valid ranges!\n"
     ]
    }
   ],
   "source": [
    "def check_invalid_scores():\n",
    "    \"\"\"\n",
    "    Check all JSON files for any self_grade_score that exceeds the max score for that question\n",
    "    or is below 0 (minimum score)\n",
    "    \"\"\"\n",
    "    issues_found = []\n",
    "    \n",
    "    print(\"Checking for invalid scores (> max_score or < 0)...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for method in methods:\n",
    "        method_dir = f\"results/{method}\"\n",
    "        \n",
    "        if os.path.exists(method_dir):\n",
    "            json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "            \n",
    "            for filepath in json_files:\n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # Extract model name from filename\n",
    "                    filename = os.path.basename(filepath)\n",
    "                    model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "                    \n",
    "                    # Check each question in the file\n",
    "                    for idx, item in enumerate(data):\n",
    "                        if 'self_grade_score' in item and item['self_grade_score'] is not None:\n",
    "                            score = item['self_grade_score']\n",
    "                            \n",
    "                            # Get the max score for this question (assuming same order)\n",
    "                            if idx < len(max_scores_per_question):\n",
    "                                max_score = max_scores_per_question[idx]\n",
    "                            else:\n",
    "                                max_score = 7  # Fallback if index out of range\n",
    "                                print(f\"‚ö†Ô∏è  Question index {idx} out of range, using default max_score=7\")\n",
    "                            \n",
    "                            # Check for invalid scores\n",
    "                            is_invalid = False\n",
    "                            issue_type = \"\"\n",
    "                            \n",
    "                            if score > max_score:\n",
    "                                is_invalid = True\n",
    "                                issue_type = f\"OVER MAX (score: {score}, max: {max_score})\"\n",
    "                            elif score < 0:\n",
    "                                is_invalid = True\n",
    "                                issue_type = f\"BELOW MIN (score: {score}, min: 0)\"\n",
    "                            \n",
    "                            if is_invalid:\n",
    "                                issue = {\n",
    "                                    'method': method,\n",
    "                                    'model': model_name,\n",
    "                                    'question_index': idx,\n",
    "                                    'score': score,\n",
    "                                    'max_score': max_score,\n",
    "                                    'issue_type': issue_type,\n",
    "                                    'file': filepath\n",
    "                                }\n",
    "                                \n",
    "                                # Try to get question text for better identification\n",
    "                                question_text = item.get('question', f\"Question_{idx}\")\n",
    "                                question_preview = question_text[:100] + \"...\" if len(question_text) > 100 else question_text\n",
    "                                issue['question_preview'] = question_preview\n",
    "                                \n",
    "                                issues_found.append(issue)\n",
    "                                \n",
    "                                print(f\"üö® ISSUE FOUND:\")\n",
    "                                print(f\"   Method: {method}\")\n",
    "                                print(f\"   Model: {model_name}\")\n",
    "                                print(f\"   Question Index: {idx}\")\n",
    "                                print(f\"   Issue: {issue_type}\")\n",
    "                                print(f\"   Question: {question_preview}\")\n",
    "                                print(f\"   File: {os.path.basename(filepath)}\")\n",
    "                                print(\"-\" * 40)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error checking {filepath}: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    if issues_found:\n",
    "        print(f\"\\n‚ö†Ô∏è  TOTAL ISSUES FOUND: {len(issues_found)}\")\n",
    "        \n",
    "        # Count by issue type\n",
    "        over_max_count = sum(1 for issue in issues_found if \"OVER MAX\" in issue['issue_type'])\n",
    "        below_min_count = sum(1 for issue in issues_found if \"BELOW MIN\" in issue['issue_type'])\n",
    "        \n",
    "        print(f\"   - Scores over maximum: {over_max_count}\")\n",
    "        print(f\"   - Scores below minimum (0): {below_min_count}\")\n",
    "        \n",
    "        print(\"\\nSummary by Model:\")\n",
    "        \n",
    "        # Group issues by model\n",
    "        from collections import defaultdict\n",
    "        issues_by_model = defaultdict(list)\n",
    "        for issue in issues_found:\n",
    "            issues_by_model[issue['model']].append(issue)\n",
    "        \n",
    "        for model, model_issues in issues_by_model.items():\n",
    "            print(f\"  {model}: {len(model_issues)} issues\")\n",
    "            for issue in model_issues:\n",
    "                print(f\"    - {issue['method']}, Q{issue['question_index']}: {issue['issue_type']}\")\n",
    "        \n",
    "        print(\"\\nSummary by Method:\")\n",
    "        issues_by_method = defaultdict(list)\n",
    "        for issue in issues_found:\n",
    "            issues_by_method[issue['method']].append(issue)\n",
    "        \n",
    "        for method, method_issues in issues_by_method.items():\n",
    "            print(f\"  {method}: {len(method_issues)} issues\")\n",
    "        \n",
    "        # Create a DataFrame for easier analysis\n",
    "        issues_df = pd.DataFrame(issues_found)\n",
    "        print(f\"\\nSaving issues to 'scoring_issues.csv'\")\n",
    "        issues_df.to_csv('scoring_issues.csv', index=False)\n",
    "        \n",
    "        return issues_found\n",
    "    else:\n",
    "        print(\"‚úÖ No invalid scores found. All scores are within valid ranges!\")\n",
    "        return []\n",
    "\n",
    "# Run the validation check\n",
    "issues = check_invalid_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ff77620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing default_essay: Found 25 files\n",
      "  codestral-latest-official: 65/149 = 0.4362 (43 questions)\n",
      "  gpt-4o: 97/149 = 0.6510 (43 questions)\n",
      "  grok-3: 100/149 = 0.6711 (43 questions)\n",
      "  groq-llama3.3-70b: 89/149 = 0.5973 (43 questions)\n",
      "  claude-sonnet-4: 95/149 = 0.6376 (43 questions)\n",
      "  claude-3.7-sonnet: 91/149 = 0.6107 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  claude-3.5-haiku: 79/149 = 0.5302 (43 questions)\n",
      "  gemini-2.5-pro: 100/149 = 0.6711 (43 questions)\n",
      "  groq-llama-4-scout: 83/149 = 0.5570 (43 questions)\n",
      "  o4-mini: 117/149 = 0.7852 (43 questions)\n",
      "  gemini-2.5-flash: 100/149 = 0.6711 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 91/149 = 0.6107 (41 questions)\n",
      "  claude-opus-4: 89/149 = 0.5973 (43 questions)\n",
      "  mistral-large-official: 78/149 = 0.5235 (43 questions)\n",
      "  gpt-4.1-mini: 83/149 = 0.5570 (43 questions)\n",
      "  groq-llama-4-maverick: 103/149 = 0.6913 (43 questions)\n",
      "  deepseek-r1: 93/149 = 0.6242 (43 questions)\n",
      "  gpt-4.1: 81/149 = 0.5436 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 101/149 = 0.6779 (43 questions)\n",
      "  gpt-4.1-nano: 64/149 = 0.4295 (43 questions)\n",
      "  o3-mini: 106/149 = 0.7114 (43 questions)\n",
      "  palmyra-fin-default: 87/149 = 0.5839 (43 questions)\n",
      "  claude-3.5-sonnet: 85/149 = 0.5705 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 61/149 = 0.4094 (43 questions)\n",
      "Processing self_consistency_essay_n3: Found 25 files\n",
      "  claude-3.7-sonnet: 101/149 = 0.6779 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 104/149 = 0.6980 (43 questions)\n",
      "  gemini-2.5-flash: 121/149 = 0.8121 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 47/149 = 0.3154 (43 questions)\n",
      "  mistral-large-official: 84/149 = 0.5638 (43 questions)\n",
      "  palmyra-fin-default: 75/149 = 0.5034 (43 questions)\n",
      "  o3-mini: 108/149 = 0.7248 (43 questions)\n",
      "  o4-mini: 124/149 = 0.8322 (43 questions)\n",
      "  grok-3: 109/149 = 0.7315 (43 questions)\n",
      "  gpt-4.1-nano: 78/149 = 0.5235 (43 questions)\n",
      "  deepseek-r1: 94/149 = 0.6309 (43 questions)\n",
      "  claude-sonnet-4: 107/149 = 0.7181 (43 questions)\n",
      "  gemini-2.5-pro: 112/149 = 0.7517 (43 questions)\n",
      "  gpt-4.1-mini: 90/149 = 0.6040 (43 questions)\n",
      "  codestral-latest-official: 51/149 = 0.3423 (43 questions)\n",
      "  gpt-4o: 91/149 = 0.6107 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 104/149 = 0.6980 (43 questions)\n",
      "  gpt-4.1: 81/149 = 0.5436 (43 questions)\n",
      "  groq-llama3.3-70b: 77/149 = 0.5168 (43 questions)\n",
      "  groq-llama-4-scout: 83/149 = 0.5570 (43 questions)\n",
      "  claude-opus-4: 114/149 = 0.7651 (43 questions)\n",
      "  claude-3.5-haiku: 91/149 = 0.6107 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  claude-3.5-sonnet: 86/149 = 0.5772 (43 questions)\n",
      "  groq-llama-4-maverick: 86/149 = 0.5772 (43 questions)\n",
      "Processing self_consistency_essay_n5: Found 25 files\n",
      "  grok-3: 113/149 = 0.7584 (43 questions)\n",
      "  gpt-4.1-nano: 74/149 = 0.4966 (43 questions)\n",
      "  o3-mini: 110/149 = 0.7383 (43 questions)\n",
      "  o4-mini: 119/149 = 0.7987 (43 questions)\n",
      "  gemini-2.5-pro: 105/149 = 0.7047 (43 questions)\n",
      "  gpt-4.1-mini: 92/149 = 0.6174 (43 questions)\n",
      "  deepseek-r1: 86/149 = 0.5772 (43 questions)\n",
      "  claude-sonnet-4: 104/149 = 0.6980 (43 questions)\n",
      "  claude-3.7-sonnet: 91/149 = 0.6107 (43 questions)\n",
      "  palmyra-fin-default: 74/149 = 0.4966 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 100/149 = 0.6711 (43 questions)\n",
      "  gemini-2.5-flash: 112/149 = 0.7517 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 69/149 = 0.4631 (43 questions)\n",
      "  mistral-large-official: 90/149 = 0.6040 (43 questions)\n",
      "  claude-opus-4: 113/149 = 0.7584 (43 questions)\n",
      "  claude-3.5-haiku: 76/149 = 0.5101 (43 questions)\n",
      "  groq-llama-4-scout: 84/149 = 0.5638 (43 questions)\n",
      "  claude-3.5-sonnet: 83/149 = 0.5570 (43 questions)\n",
      "  groq-llama-4-maverick: 97/149 = 0.6510 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  gpt-4o: 96/149 = 0.6443 (43 questions)\n",
      "  codestral-latest-official: 56/149 = 0.3758 (43 questions)\n",
      "  gpt-4.1: 86/149 = 0.5772 (43 questions)\n",
      "  groq-llama3.3-70b: 80/149 = 0.5369 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 102/149 = 0.6846 (43 questions)\n",
      "Processing self_discover_essay: Found 25 files\n",
      "  claude-opus-4: 98/149 = 0.6577 (43 questions)\n",
      "  o3-mini: 110/149 = 0.7383 (43 questions)\n",
      "  claude-3.5-haiku: 67/149 = 0.4497 (43 questions)\n",
      "  gpt-4o: 55/149 = 0.3691 (43 questions)\n",
      "  grok-3: 86/149 = 0.5772 (43 questions)\n",
      "  groq-llama-guard-4: 0/149 = 0.0000 (43 questions)\n",
      "  o4-mini: 106/149 = 0.7114 (43 questions)\n",
      "  groq-llama-4-maverick: 78/149 = 0.5235 (43 questions)\n",
      "  claude-3.7-sonnet: 91/149 = 0.6107 (43 questions)\n",
      "  grok-3-mini-beta-low-effort: 80/149 = 0.5369 (43 questions)\n",
      "  palmyra-fin-default: 49/149 = 0.3289 (43 questions)\n",
      "  groq-llama-4-scout: 63/149 = 0.4228 (43 questions)\n",
      "  gpt-4.1: 68/149 = 0.4564 (43 questions)\n",
      "  claude-sonnet-4: 86/149 = 0.5772 (43 questions)\n",
      "  grok-3-mini-beta-high-effort: 69/149 = 0.4631 (42 questions)\n",
      "  gpt-4.1-mini: 65/149 = 0.4362 (43 questions)\n",
      "  mistral-large-official: 40/149 = 0.2685 (43 questions)\n",
      "  groq-llama3.3-70b: 54/149 = 0.3624 (43 questions)\n",
      "  gemini-2.5-flash: 102/149 = 0.6846 (43 questions)\n",
      "  gemini-2.5-pro: 92/149 = 0.6174 (43 questions)\n",
      "  claude-3.5-sonnet: 83/149 = 0.5570 (43 questions)\n",
      "  deepseek-r1: 80/149 = 0.5369 (43 questions)\n",
      "  codestral-latest-official: 39/149 = 0.2617 (43 questions)\n",
      "  groq-llama3.1-8b-instant: 30/149 = 0.2013 (43 questions)\n",
      "  gpt-4.1-nano: 40/149 = 0.2685 (43 questions)\n"
     ]
    }
   ],
   "source": [
    "# Process each method directory\n",
    "for method in methods:\n",
    "    method_dir = f\"results/{method}\"\n",
    "    \n",
    "    if os.path.exists(method_dir):\n",
    "        # Find all JSON files in the directory\n",
    "        json_files = glob.glob(os.path.join(method_dir, \"evaluated_results_*.json\"))\n",
    "        \n",
    "        print(f\"Processing {method}: Found {len(json_files)} files\")\n",
    "        \n",
    "        for filepath in json_files:\n",
    "            model_name, total_score, num_questions, normalized_score = process_json_file(filepath)\n",
    "            \n",
    "            if model_name:\n",
    "                # Initialize model entry if not exists\n",
    "                if model_name not in results_data:\n",
    "                    results_data[model_name] = {}\n",
    "                \n",
    "                # Store the normalized score for this method\n",
    "                results_data[model_name][method] = normalized_score\n",
    "                \n",
    "                print(f\"  {model_name}: {total_score}/{total_possible_points} = {normalized_score:.4f} ({num_questions} questions)\")\n",
    "    else:\n",
    "        print(f\"Directory {method_dir} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39f5fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results ordered by default_essay:\n",
      "================================================================================\n",
      "                              default_essay\n",
      "o4-mini                              0.7852\n",
      "o3-mini                              0.7114\n",
      "groq-llama-4-maverick                0.6913\n",
      "grok-3-mini-beta-low-effort          0.6779\n",
      "grok-3                               0.6711\n",
      "gemini-2.5-pro                       0.6711\n",
      "gemini-2.5-flash                     0.6711\n",
      "gpt-4o                               0.6510\n",
      "claude-sonnet-4                      0.6376\n",
      "deepseek-r1                          0.6242\n",
      "grok-3-mini-beta-high-effort         0.6107\n",
      "claude-3.7-sonnet                    0.6107\n",
      "claude-opus-4                        0.5973\n",
      "groq-llama3.3-70b                    0.5973\n",
      "palmyra-fin-default                  0.5839\n",
      "claude-3.5-sonnet                    0.5705\n",
      "groq-llama-4-scout                   0.5570\n",
      "gpt-4.1-mini                         0.5570\n",
      "gpt-4.1                              0.5436\n",
      "claude-3.5-haiku                     0.5302\n",
      "mistral-large-official               0.5235\n",
      "codestral-latest-official            0.4362\n",
      "gpt-4.1-nano                         0.4295\n",
      "groq-llama3.1-8b-instant             0.4094\n",
      "groq-llama-guard-4                   0.0000\n",
      "\n",
      "Results ordered by self_consistency_essay_n3:\n",
      "================================================================================\n",
      "                              self_consistency_essay_n3\n",
      "o4-mini                                          0.8322\n",
      "gemini-2.5-flash                                 0.8121\n",
      "claude-opus-4                                    0.7651\n",
      "gemini-2.5-pro                                   0.7517\n",
      "grok-3                                           0.7315\n",
      "o3-mini                                          0.7248\n",
      "claude-sonnet-4                                  0.7181\n",
      "grok-3-mini-beta-low-effort                      0.6980\n",
      "grok-3-mini-beta-high-effort                     0.6980\n",
      "claude-3.7-sonnet                                0.6779\n",
      "deepseek-r1                                      0.6309\n",
      "claude-3.5-haiku                                 0.6107\n",
      "gpt-4o                                           0.6107\n",
      "gpt-4.1-mini                                     0.6040\n",
      "claude-3.5-sonnet                                0.5772\n",
      "groq-llama-4-maverick                            0.5772\n",
      "mistral-large-official                           0.5638\n",
      "groq-llama-4-scout                               0.5570\n",
      "gpt-4.1                                          0.5436\n",
      "gpt-4.1-nano                                     0.5235\n",
      "groq-llama3.3-70b                                0.5168\n",
      "palmyra-fin-default                              0.5034\n",
      "codestral-latest-official                        0.3423\n",
      "groq-llama3.1-8b-instant                         0.3154\n",
      "groq-llama-guard-4                               0.0000\n",
      "\n",
      "Results ordered by self_consistency_essay_n5:\n",
      "================================================================================\n",
      "                              self_consistency_essay_n5\n",
      "o4-mini                                          0.7987\n",
      "grok-3                                           0.7584\n",
      "claude-opus-4                                    0.7584\n",
      "gemini-2.5-flash                                 0.7517\n",
      "o3-mini                                          0.7383\n",
      "gemini-2.5-pro                                   0.7047\n",
      "claude-sonnet-4                                  0.6980\n",
      "grok-3-mini-beta-high-effort                     0.6846\n",
      "grok-3-mini-beta-low-effort                      0.6711\n",
      "groq-llama-4-maverick                            0.6510\n",
      "gpt-4o                                           0.6443\n",
      "gpt-4.1-mini                                     0.6174\n",
      "claude-3.7-sonnet                                0.6107\n",
      "mistral-large-official                           0.6040\n",
      "deepseek-r1                                      0.5772\n",
      "gpt-4.1                                          0.5772\n",
      "groq-llama-4-scout                               0.5638\n",
      "claude-3.5-sonnet                                0.5570\n",
      "groq-llama3.3-70b                                0.5369\n",
      "claude-3.5-haiku                                 0.5101\n",
      "palmyra-fin-default                              0.4966\n",
      "gpt-4.1-nano                                     0.4966\n",
      "groq-llama3.1-8b-instant                         0.4631\n",
      "codestral-latest-official                        0.3758\n",
      "groq-llama-guard-4                               0.0000\n",
      "\n",
      "Results ordered by self_discover_essay:\n",
      "================================================================================\n",
      "                              self_discover_essay\n",
      "o3-mini                                    0.7383\n",
      "o4-mini                                    0.7114\n",
      "gemini-2.5-flash                           0.6846\n",
      "claude-opus-4                              0.6577\n",
      "gemini-2.5-pro                             0.6174\n",
      "claude-3.7-sonnet                          0.6107\n",
      "grok-3                                     0.5772\n",
      "claude-sonnet-4                            0.5772\n",
      "claude-3.5-sonnet                          0.5570\n",
      "deepseek-r1                                0.5369\n",
      "grok-3-mini-beta-low-effort                0.5369\n",
      "groq-llama-4-maverick                      0.5235\n",
      "grok-3-mini-beta-high-effort               0.4631\n",
      "gpt-4.1                                    0.4564\n",
      "claude-3.5-haiku                           0.4497\n",
      "gpt-4.1-mini                               0.4362\n",
      "groq-llama-4-scout                         0.4228\n",
      "gpt-4o                                     0.3691\n",
      "groq-llama3.3-70b                          0.3624\n",
      "palmyra-fin-default                        0.3289\n",
      "mistral-large-official                     0.2685\n",
      "gpt-4.1-nano                               0.2685\n",
      "codestral-latest-official                  0.2617\n",
      "groq-llama3.1-8b-instant                   0.2013\n",
      "groq-llama-guard-4                         0.0000\n"
     ]
    }
   ],
   "source": [
    "# Convert results_data ‚Üí DataFrame\n",
    "df = pd.DataFrame.from_dict(results_data, orient=\"index\")\n",
    "\n",
    "# Keep columns in the desired order\n",
    "df = df.reindex(columns=methods)\n",
    "\n",
    "# Replace missing scores with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# One table per method, ordered by value\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "for method in methods:\n",
    "    ordered_tbl = (\n",
    "        df[[method]]             # keep only that method‚Äôs column\n",
    "        .sort_values(\n",
    "            by=method,\n",
    "            ascending=False      # highest score at the top\n",
    "        )\n",
    "        .round(4)\n",
    "    )\n",
    "\n",
    "    print(f\"\\nResults ordered by {method}:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(ordered_tbl.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METHOD: default_essay\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>rouge_l_precision</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "      <th>rouge_l_f1measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grok-3-mini-beta-high-effort</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grok-3</td>\n",
       "      <td>0.5592</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>groq-llama-4-maverick</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.4365</td>\n",
       "      <td>0.1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>0.0846</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>groq-llama-4-scout</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grok-3-mini-beta-low-effort</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>0.1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>palmyra-fin-default</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.7-sonnet</td>\n",
       "      <td>0.5281</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-opus-4</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.5266</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.3884</td>\n",
       "      <td>0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>groq-llama3.3-70b</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.4316</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mistral-large-official</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>0.1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.3837</td>\n",
       "      <td>0.1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codestral-latest-official</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>groq-llama3.1-8b-instant</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-4</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.4049</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3.5-haiku</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>groq-llama-guard-4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  cosine_similarity  rouge_l_precision  \\\n",
       "14  grok-3-mini-beta-high-effort             0.5667             0.0607   \n",
       "13                        grok-3             0.5592             0.0619   \n",
       "7               gemini-2.5-flash             0.5585             0.0839   \n",
       "16         groq-llama-4-maverick             0.5504             0.1065   \n",
       "22                       o3-mini             0.5471             0.1055   \n",
       "8                 gemini-2.5-pro             0.5446             0.0846   \n",
       "17            groq-llama-4-scout             0.5433             0.1065   \n",
       "6                    deepseek-r1             0.5427             0.0697   \n",
       "15   grok-3-mini-beta-low-effort             0.5405             0.0637   \n",
       "12                        gpt-4o             0.5395             0.1138   \n",
       "10                  gpt-4.1-mini             0.5381             0.0855   \n",
       "24           palmyra-fin-default             0.5376             0.1150   \n",
       "2              claude-3.7-sonnet             0.5281             0.1192   \n",
       "3                  claude-opus-4             0.5274             0.0938   \n",
       "9                        gpt-4.1             0.5266             0.0881   \n",
       "20             groq-llama3.3-70b             0.5247             0.1041   \n",
       "21        mistral-large-official             0.5236             0.1149   \n",
       "11                  gpt-4.1-nano             0.5222             0.1009   \n",
       "5      codestral-latest-official             0.5198             0.1188   \n",
       "19      groq-llama3.1-8b-instant             0.5152             0.1019   \n",
       "4                claude-sonnet-4             0.5023             0.0801   \n",
       "1              claude-3.5-sonnet             0.4905             0.1469   \n",
       "23                       o4-mini             0.4898             0.1202   \n",
       "0               claude-3.5-haiku             0.4499             0.1611   \n",
       "18            groq-llama-guard-4             0.0000             0.0000   \n",
       "\n",
       "    rouge_l_recall  rouge_l_f1measure  \n",
       "14          0.5082             0.1056  \n",
       "13          0.5033             0.1073  \n",
       "7           0.4498             0.1364  \n",
       "16          0.4412             0.1636  \n",
       "22          0.4365             0.1608  \n",
       "8           0.4548             0.1375  \n",
       "17          0.4346             0.1614  \n",
       "6           0.4949             0.1172  \n",
       "15          0.4839             0.1090  \n",
       "12          0.4014             0.1686  \n",
       "10          0.4278             0.1365  \n",
       "24          0.4090             0.1652  \n",
       "2           0.4111             0.1746  \n",
       "3           0.4147             0.1470  \n",
       "9           0.3884             0.1371  \n",
       "20          0.4316             0.1585  \n",
       "21          0.4007             0.1651  \n",
       "11          0.3837             0.1519  \n",
       "5           0.3995             0.1684  \n",
       "19          0.4260             0.1553  \n",
       "4           0.4049             0.1298  \n",
       "1           0.3706             0.1992  \n",
       "23          0.3758             0.1684  \n",
       "0           0.3105             0.1978  \n",
       "18          0.0000             0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METHOD: self_consistency_essay_n3\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>rouge_l_precision</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "      <th>rouge_l_f1measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.5661</td>\n",
       "      <td>0.0774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grok-3</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.5637</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grok-3-mini-beta-high-effort</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.4729</td>\n",
       "      <td>0.1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-opus-4</td>\n",
       "      <td>0.5465</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>0.1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>groq-llama3.3-70b</td>\n",
       "      <td>0.5458</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>palmyra-fin-default</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>groq-llama-4-scout</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.7-sonnet</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>groq-llama-4-maverick</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.4354</td>\n",
       "      <td>0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grok-3-mini-beta-low-effort</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistral-large-official</td>\n",
       "      <td>0.5389</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>groq-llama3.1-8b-instant</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.4524</td>\n",
       "      <td>0.1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.5285</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-4</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codestral-latest-official</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.4159</td>\n",
       "      <td>0.1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3.5-haiku</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.1725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  cosine_similarity  rouge_l_precision  \\\n",
       "7               gemini-2.5-flash             0.5793             0.0470   \n",
       "8                 gemini-2.5-pro             0.5695             0.0427   \n",
       "13                        grok-3             0.5674             0.0522   \n",
       "10                  gpt-4.1-mini             0.5637             0.0633   \n",
       "14  grok-3-mini-beta-high-effort             0.5562             0.0363   \n",
       "21                       o3-mini             0.5559             0.0700   \n",
       "9                        gpt-4.1             0.5482             0.0732   \n",
       "3                  claude-opus-4             0.5465             0.0751   \n",
       "19             groq-llama3.3-70b             0.5458             0.0847   \n",
       "23           palmyra-fin-default             0.5455             0.0824   \n",
       "17            groq-llama-4-scout             0.5437             0.0890   \n",
       "2              claude-3.7-sonnet             0.5410             0.0691   \n",
       "16         groq-llama-4-maverick             0.5403             0.0951   \n",
       "15   grok-3-mini-beta-low-effort             0.5403             0.0403   \n",
       "20        mistral-large-official             0.5389             0.0821   \n",
       "6                    deepseek-r1             0.5383             0.0664   \n",
       "12                        gpt-4o             0.5343             0.0962   \n",
       "18      groq-llama3.1-8b-instant             0.5287             0.0787   \n",
       "11                  gpt-4.1-nano             0.5285             0.0775   \n",
       "4                claude-sonnet-4             0.5238             0.0745   \n",
       "5      codestral-latest-official             0.5229             0.0882   \n",
       "1              claude-3.5-sonnet             0.5091             0.1062   \n",
       "22                       o4-mini             0.4939             0.1044   \n",
       "0               claude-3.5-haiku             0.4348             0.1274   \n",
       "\n",
       "    rouge_l_recall  rouge_l_f1measure  \n",
       "7           0.5520             0.0847  \n",
       "8           0.5661             0.0774  \n",
       "13          0.5344             0.0933  \n",
       "10          0.5024             0.1091  \n",
       "14          0.5714             0.0674  \n",
       "21          0.4729             0.1177  \n",
       "9           0.4620             0.1224  \n",
       "3           0.4571             0.1256  \n",
       "19          0.4426             0.1367  \n",
       "23          0.4380             0.1330  \n",
       "17          0.4526             0.1412  \n",
       "2           0.4893             0.1172  \n",
       "16          0.4354             0.1504  \n",
       "15          0.5380             0.0738  \n",
       "20          0.4403             0.1327  \n",
       "6           0.4773             0.1132  \n",
       "12          0.4036             0.1490  \n",
       "18          0.4524             0.1297  \n",
       "11          0.4425             0.1270  \n",
       "4           0.4438             0.1241  \n",
       "5           0.4159             0.1379  \n",
       "1           0.3849             0.1592  \n",
       "22          0.3850             0.1491  \n",
       "0           0.3180             0.1725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METHOD: self_consistency_essay_n5\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>rouge_l_precision</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "      <th>rouge_l_f1measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>0.5723</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grok-3</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>0.5639</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grok-3-mini-beta-high-effort</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>palmyra-fin-default</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>groq-llama3.3-70b</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.4173</td>\n",
       "      <td>0.1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistral-large-official</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>groq-llama-4-maverick</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.7-sonnet</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grok-3-mini-beta-low-effort</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-opus-4</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codestral-latest-official</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.4226</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>groq-llama-4-scout</td>\n",
       "      <td>0.5324</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-4</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>groq-llama3.1-8b-instant</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0.5101</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3.5-haiku</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.1701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  cosine_similarity  rouge_l_precision  \\\n",
       "7               gemini-2.5-flash             0.5723             0.0495   \n",
       "10                  gpt-4.1-mini             0.5690             0.0654   \n",
       "13                        grok-3             0.5648             0.0530   \n",
       "8                 gemini-2.5-pro             0.5639             0.0432   \n",
       "14  grok-3-mini-beta-high-effort             0.5627             0.0358   \n",
       "9                        gpt-4.1             0.5545             0.0711   \n",
       "21                       o3-mini             0.5493             0.0706   \n",
       "6                    deepseek-r1             0.5474             0.0653   \n",
       "23           palmyra-fin-default             0.5460             0.0829   \n",
       "19             groq-llama3.3-70b             0.5459             0.0850   \n",
       "12                        gpt-4o             0.5431             0.0967   \n",
       "20        mistral-large-official             0.5413             0.0818   \n",
       "16         groq-llama-4-maverick             0.5408             0.0971   \n",
       "2              claude-3.7-sonnet             0.5406             0.0691   \n",
       "15   grok-3-mini-beta-low-effort             0.5399             0.0404   \n",
       "3                  claude-opus-4             0.5390             0.0751   \n",
       "5      codestral-latest-official             0.5342             0.0863   \n",
       "17            groq-llama-4-scout             0.5324             0.0827   \n",
       "4                claude-sonnet-4             0.5316             0.0741   \n",
       "18      groq-llama3.1-8b-instant             0.5286             0.0812   \n",
       "11                  gpt-4.1-nano             0.5282             0.0720   \n",
       "1              claude-3.5-sonnet             0.5101             0.1046   \n",
       "22                       o4-mini             0.4892             0.1168   \n",
       "0               claude-3.5-haiku             0.4278             0.1257   \n",
       "\n",
       "    rouge_l_recall  rouge_l_f1measure  \n",
       "7           0.5450             0.0887  \n",
       "10          0.5060             0.1124  \n",
       "13          0.5376             0.0945  \n",
       "8           0.5526             0.0784  \n",
       "14          0.5689             0.0665  \n",
       "9           0.4579             0.1195  \n",
       "21          0.4651             0.1179  \n",
       "6           0.4902             0.1103  \n",
       "23          0.4362             0.1336  \n",
       "19          0.4490             0.1375  \n",
       "12          0.4173             0.1506  \n",
       "20          0.4488             0.1330  \n",
       "16          0.4454             0.1537  \n",
       "2           0.4890             0.1174  \n",
       "15          0.5395             0.0740  \n",
       "3           0.4533             0.1255  \n",
       "5           0.4226             0.1370  \n",
       "17          0.4404             0.1343  \n",
       "4           0.4462             0.1237  \n",
       "18          0.4550             0.1324  \n",
       "11          0.4396             0.1202  \n",
       "1           0.3833             0.1573  \n",
       "22          0.3858             0.1597  \n",
       "0           0.3150             0.1701  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METHOD: self_discover_essay\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>rouge_l_precision</th>\n",
       "      <th>rouge_l_recall</th>\n",
       "      <th>rouge_l_f1measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>0.0704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>0.5654</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>0.0741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grok-3</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.0795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>o3-mini</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3.7-sonnet</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.0962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>0.5456</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>groq-llama-4-scout</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>0.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>palmyra-fin-default</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>groq-llama-4-maverick</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-opus-4</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>groq-llama3.3-70b</td>\n",
       "      <td>0.5311</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grok-3-mini-beta-high-effort</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.0562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mistral-large-official</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0.1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grok-3-mini-beta-low-effort</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.0962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codestral-latest-official</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.4376</td>\n",
       "      <td>0.1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-sonnet-4</td>\n",
       "      <td>0.5032</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.4661</td>\n",
       "      <td>0.0987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>groq-llama3.1-8b-instant</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.4447</td>\n",
       "      <td>0.0939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>0.0994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-3.5-sonnet</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-3.5-haiku</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>groq-llama-guard-4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  cosine_similarity  rouge_l_precision  \\\n",
       "8                 gemini-2.5-pro             0.5691             0.0381   \n",
       "7               gemini-2.5-flash             0.5654             0.0404   \n",
       "13                        grok-3             0.5607             0.0437   \n",
       "22                       o3-mini             0.5532             0.0494   \n",
       "2              claude-3.7-sonnet             0.5461             0.0546   \n",
       "9                        gpt-4.1             0.5456             0.0551   \n",
       "10                  gpt-4.1-mini             0.5411             0.0464   \n",
       "17            groq-llama-4-scout             0.5388             0.0613   \n",
       "24           palmyra-fin-default             0.5381             0.0579   \n",
       "6                    deepseek-r1             0.5329             0.0661   \n",
       "16         groq-llama-4-maverick             0.5317             0.0694   \n",
       "3                  claude-opus-4             0.5313             0.0582   \n",
       "20             groq-llama3.3-70b             0.5311             0.0601   \n",
       "14  grok-3-mini-beta-high-effort             0.5265             0.0311   \n",
       "21        mistral-large-official             0.5260             0.0602   \n",
       "12                        gpt-4o             0.5222             0.0693   \n",
       "15   grok-3-mini-beta-low-effort             0.5208             0.0328   \n",
       "11                  gpt-4.1-nano             0.5192             0.0551   \n",
       "5      codestral-latest-official             0.5183             0.0595   \n",
       "4                claude-sonnet-4             0.5032             0.0565   \n",
       "19      groq-llama3.1-8b-instant             0.4948             0.0538   \n",
       "23                       o4-mini             0.4928             0.0574   \n",
       "1              claude-3.5-sonnet             0.4910             0.1024   \n",
       "0               claude-3.5-haiku             0.4312             0.0871   \n",
       "18            groq-llama-guard-4             0.0000             0.0000   \n",
       "\n",
       "    rouge_l_recall  rouge_l_f1measure  \n",
       "8           0.5675             0.0704  \n",
       "7           0.5454             0.0741  \n",
       "13          0.5371             0.0795  \n",
       "22          0.5075             0.0881  \n",
       "2           0.5110             0.0962  \n",
       "9           0.4812             0.0968  \n",
       "10          0.5016             0.0837  \n",
       "17          0.4743             0.1060  \n",
       "24          0.4804             0.1012  \n",
       "6           0.4733             0.1113  \n",
       "16          0.4579             0.1158  \n",
       "3           0.4699             0.1014  \n",
       "20          0.4686             0.1037  \n",
       "14          0.5474             0.0562  \n",
       "21          0.4655             0.1039  \n",
       "12          0.4280             0.1159  \n",
       "15          0.5413             0.0612  \n",
       "11          0.4556             0.0962  \n",
       "5           0.4376             0.1022  \n",
       "4           0.4661             0.0987  \n",
       "19          0.4447             0.0939  \n",
       "23          0.4482             0.0994  \n",
       "1           0.3796             0.1537  \n",
       "0           0.3572             0.1345  \n",
       "18          0.0000             0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to extract similarity scores from a result file\n",
    "def extract_similarity_scores(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract model name from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    model_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[0]\n",
    "    method_name = filename.replace('evaluated_results_', '').replace('.json', '').split('__')[1] if '__' in filename else 'unknown'\n",
    "    \n",
    "    scores = []\n",
    "    for entry in data:\n",
    "        if not entry.get(\"error\"):\n",
    "            score_entry = {\n",
    "                'model': model_name,\n",
    "                'method': method_name,\n",
    "                'cosine_similarity': entry.get('cosine_similarity'),\n",
    "                'rouge_l_precision': entry.get('rouge_l_precision'),\n",
    "                'rouge_l_recall': entry.get('rouge_l_recall'),\n",
    "                'rouge_l_f1measure': entry.get('rouge_l_f1measure')\n",
    "            }\n",
    "            scores.append(score_entry)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Get scores from all result files\n",
    "all_scores = []\n",
    "results_dir = Path(\"results\")\n",
    "\n",
    "for method_dir in results_dir.iterdir():\n",
    "    if not method_dir.is_dir() or method_dir.name == 'comparison_charts':\n",
    "        continue\n",
    "        \n",
    "    for file_path in method_dir.glob(\"evaluated_results_*.json\"):\n",
    "        if file_path.name.endswith('.backup'):\n",
    "            continue\n",
    "        scores = extract_similarity_scores(file_path)\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "# Create DataFrame\n",
    "scores_df = pd.DataFrame(all_scores)\n",
    "\n",
    "# Expected methods\n",
    "methods = ['default_essay', 'self_consistency_essay_n3', 'self_consistency_essay_n5', 'self_discover_essay']\n",
    "\n",
    "# For each method, display one table with all scores as columns\n",
    "for method in methods:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {method}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Filter scores for this method\n",
    "    method_scores = scores_df[scores_df['method'] == method]\n",
    "    \n",
    "    if len(method_scores) == 0:\n",
    "        print(f\"No scores found for method: {method}\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate average scores by model for this method\n",
    "    avg_scores = method_scores.groupby(['model']).agg({\n",
    "        'cosine_similarity': 'mean',\n",
    "        'rouge_l_precision': 'mean',\n",
    "        'rouge_l_recall': 'mean',\n",
    "        'rouge_l_f1measure': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Round for better display\n",
    "    avg_scores = avg_scores.round(4)\n",
    "    \n",
    "    # Sort by cosine similarity (highest first)\n",
    "    sorted_table = avg_scores.sort_values('', ascending=False)\n",
    "    \n",
    "    # Display the table\n",
    "    display(sorted_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

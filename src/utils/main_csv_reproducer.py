import sys
from pathlib import Path
_project_root = Path(__file__).resolve().parent.parent.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))
import os
import json
import csv
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
try:
    from src.main import AVAILABLE_STRATEGIES
except ImportError as e_main:
    AVAILABLE_STRATEGIES = {}
    logging.warning(f"Could not import AVAILABLE_STRATEGIES from src.main: {e_main}. Strategy names in CSV might be keys instead of full names.")
try:
    from src.evaluations.cost_evaluation import calculate_model_cost 
    from src.configs import DEFAULT_CONFIGS 
except ImportError as e_cost:
    calculate_model_cost = None
    DEFAULT_CONFIGS = []
    logging.warning(f"Could not import cost_evaluation or DEFAULT_CONFIGS: {e_cost}. API cost will not be calculated.")
logger = logging.getLogger(__name__)
CSV_HEADERS = [
    'model', 'strategy', 'run_timestamp', 'question_id',
    'cosine_similarity', 'self_grade_score',
    'rouge_l_precision', 'rouge_l_recall', 'rouge_l_f1measure',
    'latency_ms', 'input_tokens', 'output_tokens', 'api_cost',
    'answer_length', 'error'
]

STRATEGY_SORT_ORDER = [
    "Default Essay (Single Pass)",
    "Self-Consistency Essay (N=3 samples)",
    "Self-Consistency Essay (N=5 samples)",
    "Self-Discover Essay"
]

def get_model_config_by_id(config_id: str, model_configs: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    """Helper function to find a model's configuration by its config_id."""
    for mc in model_configs:
        if mc.get('config_id') == config_id or mc.get('model_id') == config_id:
            return mc
    return None

def parse_filename(filename: str) -> Optional[Dict[str, str]]:
    """Parses model_id and strategy_key from a filename like 'evaluated_results_claude-3.5-haiku__default_essay.json'."""
    if not filename.startswith("evaluated_results_") or not filename.endswith(".json"):
        return None
    parts_str = filename[len("evaluated_results_"):-len(".json")]
    split_parts = parts_str.split("__")
    if len(split_parts) != 2:
        logger.warning(f"Filename {filename} does not match expected format 'evaluated_results_MODEL__STRATEGY.json'. Found parts: {split_parts}")
        return None    
    model_id, strategy_key = split_parts
    return {"model_id": model_id, "strategy_key": strategy_key}

def get_strategy_name(strategy_key: str) -> str:
    """Gets the full strategy name from AVAILABLE_STRATEGIES or defaults to the key."""
    return AVAILABLE_STRATEGIES.get(strategy_key, {}).get("name", strategy_key)

def create_main_style_csv(results_base_dir: str, output_csv_path: str) -> None:
    """
    Recreates a CSV file similar to 'all_results.csv' generated by main.py,
    by reading from individual 'evaluated_results_*.json' files.
    Now includes per-item API cost calculation and sorts by strategy.
    """
    results_path = Path(results_base_dir)
    output_file = Path(output_csv_path)
    run_timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    logger.info(f"Starting CSV aggregation. Output will be: {output_file}")
    all_rows_data = []
    for strategy_dir in results_path.iterdir():
        if strategy_dir.is_dir():
            logger.info(f"Scanning strategy directory: {strategy_dir.name}")
            for json_file_path in strategy_dir.glob("evaluated_results_*.json"):
                logger.debug(f"Found JSON file: {json_file_path.name}")
                
                parsed_name = parse_filename(json_file_path.name)
                if not parsed_name:
                    logger.warning(f"Could not parse model/strategy from filename: {json_file_path.name}. Skipping.")
                    continue
                
                model_id_from_file = parsed_name["model_id"]
                strategy_key_from_file = parsed_name["strategy_key"]
                strategy_name_display = get_strategy_name(strategy_key_from_file)
                model_config_for_cost = None
                if calculate_model_cost and DEFAULT_CONFIGS:
                    model_config_for_cost = get_model_config_by_id(model_id_from_file, DEFAULT_CONFIGS)
                    if not model_config_for_cost:
                        logger.warning(f"Could not find model config for {model_id_from_file} to calculate cost. API cost will be None for items from {json_file_path.name}")
                
                try:
                    with open(json_file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)          
                    
                    records_to_process = data if isinstance(data, list) else data.get("results", [])
                    
                    if not records_to_process:
                        logger.info(f"No records found or 'results' key missing in {json_file_path.name}")
                        continue

                    for item in records_to_process:
                        api_cost_value = None
                        if calculate_model_cost and model_config_for_cost and item.get('input_tokens') is not None and item.get('output_tokens') is not None:
                            
                            cost_dict = calculate_model_cost([item], model_config_for_cost)
                            api_cost_value = cost_dict.get('total_cost')
                        elif calculate_model_cost and not model_config_for_cost:
                             logger.debug(f"Skipping cost for item in {json_file_path.name} due to missing model_config for {model_id_from_file}")
                        row = {
                            'model': model_id_from_file,
                            'strategy': strategy_name_display,
                            'run_timestamp': run_timestamp,
                            'question_id': item.get('question_hash', item.get('question_id', 'unknown')),
                            'cosine_similarity': item.get('cosine_similarity'),
                            'self_grade_score': item.get('self_grade_score'),
                            'rouge_l_precision': item.get('rouge_l_precision'),
                            'rouge_l_recall': item.get('rouge_l_recall'),
                            'rouge_l_f1measure': item.get('rouge_l_f1measure'),
                            'latency_ms': item.get('response_time_ms', item.get('response_time', 0) * 1000 if item.get('response_time') else None), 
                            'input_tokens': item.get('input_tokens'),
                            'output_tokens': item.get('output_tokens'),
                            'api_cost': api_cost_value,
                            'answer_length': len(item.get('cleaned_llm_answer', '')) if item.get('cleaned_llm_answer') else None,
                            'error': item.get('error')
                        }
                        all_rows_data.append(row)
                except json.JSONDecodeError:
                    logger.error(f"Error decoding JSON from {json_file_path}. Skipping.")
                except Exception as e:
                    logger.error(f"Unexpected error processing {json_file_path}: {e}. Skipping.", exc_info=True)
    
    if not all_rows_data:
        logger.warning("No data found to write to CSV.")
        return
    
    def get_strategy_sort_key(row):
        try:
            return STRATEGY_SORT_ORDER.index(row['strategy'])
        except ValueError:            
            return len(STRATEGY_SORT_ORDER)

    all_rows_data.sort(key=lambda row: (get_strategy_sort_key(row), row['model'], row['question_id']))
    logger.info(f"Sorted {len(all_rows_data)} rows based on strategy order, then model, then question_id.")

    try:
        output_file.parent.mkdir(parents=True, exist_ok=True) 
        with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:
            writer = csv.DictWriter(csv_file, fieldnames=CSV_HEADERS)
            writer.writeheader()
            writer.writerows(all_rows_data)
        logger.info(f"Successfully created aggregated CSV with {len(all_rows_data)} rows at {output_file}")
    except Exception as e:
        logger.error(f"Error writing CSV to {output_file}: {e}", exc_info=True)

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    results_dir = _project_root / "results"
    output_csv = results_dir / "all_results_reproduced.csv"
    if not results_dir.exists():
        logger.error(f"Results directory not found: {results_dir}")
        exit(1)
        
    logger.info(f"Project root detected as: {_project_root}")
    logger.info(f"Reading from results directory: {results_dir}")
    logger.info(f"Outputting CSV to: {output_csv}")
    
    create_main_style_csv(str(results_dir), str(output_csv))
    logger.info("Script finished.") 